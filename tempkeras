def build_model():
    model = keras.Sequential([
            keras.layers.Dense(64, activation=tf.nn.relu,
                       input_shape=(train_data.shape[1],)),
                               keras.layers.Dense(64, activation=tf.nn.relu),
                               keras.layers.Dense(1)
                               ])
    model.compile(loss='mse', optimizer=tf.train.RMSPropOptimizer(0.001)
    ,metrics=['mae'])
    return model


model = build_model()
model.summary()



# Display training progress by printing a single dot for each completed epoch.
class PrintDot(keras.callbacks.Callback):
  def on_epoch_end(self,epoch,logs):
    if epoch % 100 == 0: print('#')
    print('.', end='#')

EPOCHS = 500

# Store training stats
history = model.fit(train_data, train_labels, epochs=EPOCHS,
                    validation_split=0.2, verbose=0,
                    callbacks=[PrintDot()])



history = model.fit(train_data, train_labels, epochs=500,
                    validation_split=0.2, verbose=1)
model = build_model()

# The patience parameter is the amount of epochs to check for improvement
early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=20)

history = model.fit(train_data, train_labels, epochs=EPOCHS,
                    validation_split=0.2, verbose=0,
                    callbacks=[early_stop, PrintDot()])

plot_history(history)
